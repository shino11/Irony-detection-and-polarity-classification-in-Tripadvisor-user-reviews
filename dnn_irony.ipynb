{ 
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jpDVYVg_RO8ZrjSIIz6vXsuiOyPQDzh9",
      "authorship_tag": "ABX9TyNa9vxuo6S8XjOPvpopm3S5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shino11/Irony-detection-and-polarity-classification-in-Tripadvisor-user-reviews./blob/main/sgd_dnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Montar Drive"
      ],
      "metadata": {
        "id": "TfimqqnGDNMu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3rJy6BnRWoY",
        "outputId": "6b97ac6d-97b9-4b4b-888d-12becf138a3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install & Verification"
      ],
      "metadata": {
        "id": "rwvXrdLtDTGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow==2.2 \n",
        "!pip install -U numpy==1.19.5\n",
        "!pip install h5py==2.10.0\n",
        "\n",
        "\n",
        "#!pip uninstall tensorflow\n",
        "#!pip install tensorflow\n",
        "#!pip uninstall numpy\n",
        "#!pip install numpy\n",
        "#!apt-get install python3.7\n",
        "\n",
        "#import sys\n",
        "#import tensorflow as tf\n",
        "\n",
        "\n",
        "#tf.__version__\n",
        "#!python3 ‐‐version\n",
        "#print(sys.version)\n",
        "\n",
        "# !pip show scikit-learn pandas tensorflow numpy"
      ],
      "metadata": {
        "id": "rqS7jORZT7Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dnn_Algorithm_Part1"
      ],
      "metadata": {
        "id": "Mv7ozKCSETV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "from builtins import print\n",
        "import numpy as np\n",
        "#import keras\n",
        "import tensorflow as tf\n",
        "#print('la version de tensorflow es:'+tf.__version__)\n",
        "import pandas as pd\n",
        "#from keras import Model\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#from tensorflow.core.protobuf import rewriter_config_pb2\n",
        "import os\n",
        "# from keras.engine.saving import model_from_json\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Flatten, Lambda\n",
        "# from keras.layers import LSTM, Input\n",
        "# from keras.layers import Dense, Embedding, Reshape\n",
        "# from keras.layers.wrappers import TimeDistributed\n",
        "# from keras.preprocessing.text import Tokenizer\n",
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "#from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, balanced_accuracy_score, classification_report\n",
        "#from statsmodels.sandbox.distributions.examples.ex_mvelliptical import fig\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.python.keras.layers.core import Dropout, RepeatVector\n",
        "from tensorflow.keras.layers import LSTM, Reshape\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten, LeakyReLU\n",
        "#from tensorflow.python.keras.engine.saving import model_from_json\n",
        "from tensorflow.python.training.adam import AdamOptimizer\n",
        "from tensorflow.keras import Input\n",
        "#from tensorflow_core.python.keras.layers import concatenate, Concatenate, Bidirectional\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.python.keras.models import load_model\n",
        "#import matplotlib #linux\n",
        "#matplotlib.use('Agg') #linux\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported).\n",
        " # The versions of TensorFlow you are currently using is 2.2.0 and is not supported.\n",
        "# import tensorflow_addons as tfa\n",
        "# import tqdm\n",
        "# # quietly deep-reload tqdm\n",
        "# import sys\n",
        "# from IPython.lib import deepreload\n",
        "# stdout = sys.stdout\n",
        "# sys.stdout = open('junk','w')\n",
        "# deepreload.reload(tqdm)\n",
        "# sys.stdout = stdout\n",
        "# tqdm_callback = tfa.callbacks.TQDMProgressBar()\n",
        "\n",
        "# import sys\n",
        "# sys.stdout = open(\"test.txt\", \"w\")\n",
        "\n",
        "#class HLSTM:\n",
        "#with tf.device('/gpu:0'):\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "#MAX_NB_WORDS = 100000\n",
        "text = []\n",
        "labels = []\n",
        "\n",
        "#activation='LeakyRelu'\n",
        "activation='selu'\n",
        "# activation='relu'\n",
        "optimizer = 'Adadelta'\n",
        "# optimizer = 'Adam'\n",
        "#learning_rate = 0.00001\n",
        "#optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "#optimizer = tf.keras.optimizers.Adadelta(learning_rate=learning_rate)\n",
        "dropout = 0.5\n",
        "neurons = 16\n",
        "patience = 10\n",
        "epochs = 16\n",
        "batch_size = 128\n",
        "folds = 5\n",
        "\n",
        "def save_model(model, filename):\n",
        "    model_json = model.to_json()\n",
        "    with open(filename + '.model', \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "        json_file.close();\n",
        "    model.save_weights(filename + \".weights\")\n",
        "\n",
        "\n",
        "# def load_model(filename):\n",
        "#     json_file = open(filename + '.model', 'r')\n",
        "#     loaded_model_json = json_file.read()\n",
        "#     json_file.close()\n",
        "#     # loaded_model = model_from_json(loaded_model_json)\n",
        "#     # loaded_model.load_weights(filename + \".weights\")\n",
        "#     # return loaded_model;\n",
        "\n",
        "\n",
        "def getEmbeddingLayer():\n",
        "    embeddings_index = {}\n",
        "    countt = 0\n",
        "    words = []\n",
        "    #f = open('data/word_embeddings/glove.840B.300d.txt', encoding='utf-8', errors='ignore')\n",
        "    #f = open('data/word_embeddings/glove.6B.100d.txt', encoding='utf-8')\n",
        "    f = open('/content/drive/MyDrive/Colab Notebooks/TestCode/glove.6B.100d.txt')\n",
        "    #f = open('word_embeddings/glove.6B.100d.txt')\n",
        "\n",
        "    for line in f:\n",
        "        values = line.split()  #espacio para glove 840b only\n",
        "        word = values[0]\n",
        "        words.append(word)\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "        countt = countt + 1;\n",
        "    f.close()\n",
        "\n",
        "    # fin = io.open('data/word_embeddings/GoogleNews-vectors-negative300.bin', 'r', encoding='utf-8', newline='\\n',\n",
        "    #               errors='ignore')\n",
        "    # n, d = map(int, fin.readline().split())\n",
        "    # for line in fin:\n",
        "    #     tokens = line.rstrip().split(' ')\n",
        "    #     word = tokens[0]\n",
        "    #     words.append(word)\n",
        "    #     embeddings_index[tokens[0]] = map(float, tokens[1:])\n",
        "    #     count += 1\n",
        "    # fin.close()\n",
        "\n",
        "    #tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "    tokenizer = Tokenizer(num_words=len(words)+1)\n",
        "    tokenizer.fit_on_texts(words)\n",
        "    word_index = tokenizer.word_index\n",
        "    vocab_size = len(word_index) + 1\n",
        "\n",
        "    print(\"total words embeddings is \", countt, len(word_index))\n",
        "    embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        # if i > vocab_size - 1:\n",
        "        #     break\n",
        "        # else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    embedding_layer = Embedding(input_dim=vocab_size,\n",
        "                                output_dim=EMBEDDING_DIM,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=False)\n",
        "\n",
        "    return tokenizer, embedding_layer\n",
        "\n",
        "\n",
        "# seed = 7346\n",
        "# np.random.seed(seed)\n",
        "count = 0\n",
        "precision_list = list()\n",
        "recall_list = list()\n",
        "accuracy_list = list()\n",
        "f1_list = list()\n",
        "\n",
        "\n",
        "def create_embedded_model(embedding_layer, num_classes, MAX_SEQUENCE_LENGTH):\n",
        "    input = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
        "    emb_layer = embedding_layer(input)\n",
        "    #model.add(tf.keras.layers.Dense(32, kernel_initializer='lecun_normal', activation='selu'))\n",
        "    out = Flatten()(emb_layer)\n",
        "    #out = Dense(32, kernel_initializer='lecun_normal', activation='selu')(out)\n",
        "    out = Dense(neurons, kernel_initializer='lecun_normal', activation=activation)(out)\n",
        "    #out = Dense(neurons, kernel_initializer='lecun_normal')(out)\n",
        "    #out = LeakyReLU()(out)\n",
        "    out = Dropout(rate=dropout)(out)\n",
        "    output = Dense(2, activation='sigmoid')(out)\n",
        "    modell = Model(input, output)\n",
        "    print(modell.summary())\n",
        "    return modell;\n",
        "\n",
        "\n",
        "# Start here\n",
        "\n",
        "dataframe = pd.DataFrame()\n",
        "#dataframe = pd.read_csv(\"./data/sgd single-domains/sgd_act_Flights.csv\", encoding='ISO-8859-1', sep='^', engine='python')\n",
        "#dataframe = pd.read_csv(\"./data/sgd single-domains/sgd_act_Alarm.csv\", encoding='ISO-8859-1', sep='^', engine='python')\n",
        "#dataframe = pd.read_csv(\"data/sgd single-domains/sgd-act-prec1-Flights.csv\", encoding='ISO-8859-1', sep='^', engine='python')\n",
        "dataframe = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/sarcasm_v2(0-1).csv\", encoding='ISO-8859-1', sep=',', engine='python')\n",
        "#dataframe = pd.read_csv(\"sarcasm_v2(0-1).csv\", encoding='ISO-8859-1', sep=',', engine='python')\n",
        "\n",
        "print(dataframe.head())\n",
        "# dataframe = dataframe.replace(to_replace=r'\\s,,\\s', value=' ')\n",
        "print(dataframe.size)\n",
        "\n",
        "# cols = ['dialogue','text','label']\n",
        "# cols = ['dialogue', 'text', 'prec_utt', 'prec_intent', 'label']\n",
        "cols = ['Corpus', 'Label', 'ID', 'Quote Text', 'Response Text']\n",
        "\n",
        "dataframe.columns = cols\n",
        "#D = dataframe.loc[:, 'dialogue']\n",
        "X = dataframe.loc[:, 'Response Text']\n",
        "# A = dataframe.loc[:, 'prec_utt']\n",
        "B = dataframe.loc[:, 'Quote Text']\n",
        "Y = dataframe.loc[:, 'Label']\n",
        "print(dataframe.shape)\n",
        "#X = X.reshape((len(X),1))\n",
        "\n",
        "X_featured = []\n",
        "for i in range(X.count()):\n",
        "    X_featured.append(X[i] + ' ' + B[i])\n",
        "\t  #X_featured.append(X[i] + ' ' + A[i] + ' ' + B[i])\n",
        "X_featured = np.reshape(X_featured, X.shape)\n",
        "#print(X_featured.shape)\n",
        "#print(dataframe.shape)\n",
        "# X = X.reshape((len(X),1))\n",
        "print(X.count())\n",
        "print(Y.count())\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = max([len(s.split()) for s in X])\n",
        "tokenizer, embedding = getEmbeddingLayer()\n",
        "\n",
        "sequences_x = tokenizer.texts_to_sequences(X_featured) #X_featured\n",
        "# sequences_a = tokenizer.texts_to_sequences(A)\n",
        "# sequences_b = tokenizer.texts_to_sequences(B)\n",
        "#sequences_a2 = tokenizer.texts_to_sequences(A2)\n",
        "#sequences_b2 = tokenizer.texts_to_sequences(B2)\n",
        "\n",
        "#dd = pad_sequences(sequences_d, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "xx = pad_sequences(sequences_x, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating=\"post\")\n",
        "# aa = pad_sequences(sequences_a, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "# bb = pad_sequences(sequences_b, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "#aa2 = pad_sequences(sequences_a2, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "#bb2 = pad_sequences(sequences_b2, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "# d = np.transpose(d)\n",
        "data = xx\n",
        "#print(data)\n",
        "uniques, ids = np.unique(Y, return_inverse=True)\n",
        "y_train = tf.keras.utils.to_categorical(ids, len(uniques))\n",
        "# y_train = np.reshape(y_train, (Y.count(),len(uniques)))\n",
        "# y_train = keras.utils.to_categorical(Y,Y.count())\n",
        "#print(len(uniques))\n",
        "#print(y_train)\n",
        "# y_train = np.array(y_train.shape[1])\n",
        "# df = pd.DataFrame(data=y_train.data)\n",
        "# y_train = np.asarray(Y)\n",
        "\n"
      ],
      "metadata": {
        "id": "HHLAP8SWgRS7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0777c1-cfbc-4f37-81dd-1ecc9dcae896"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Corpus  Label             ID  \\\n",
            "0    GEN      1  GEN_sarc_0000   \n",
            "1    GEN      1  GEN_sarc_0001   \n",
            "2    GEN      1  GEN_sarc_0002   \n",
            "3    GEN      1  GEN_sarc_0003   \n",
            "4    GEN      1  GEN_sarc_0004   \n",
            "\n",
            "                                          Quote Text  \\\n",
            "0  First off, That's grade A USDA approved Libera...   \n",
            "1  watch it. Now you're using my lines. Poet has ...   \n",
            "2  Because it will encourage teens to engage in r...   \n",
            "3  Obviously you missed the point. So sorry the t...   \n",
            "4  This is pure paranoia. What evidence do you ha...   \n",
            "\n",
            "                                       Response Text  \n",
            "0  Therefore you accept that the Republican party...  \n",
            "1  More chattering from the peanut gallery? Haven...  \n",
            "2  Yep, suppressing natural behavior is always th...  \n",
            "3  I guess we all missed your point Justine, what...  \n",
            "4  Evidence, I dont need no sticking evidence. Th...  \n",
            "23460\n",
            "(4692, 5)\n",
            "4692\n",
            "4692\n",
            "total words embeddings is  400000 339251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DNN_Algorithm_Part2"
      ],
      "metadata": {
        "id": "RRDxfRMqEdku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training data\")\n",
        "print(data.shape, y_train.shape)\n",
        "\n",
        "# np.random.seed(1)\n",
        "# y = np.random.randint(0, len(num_classes)-1, y_train.shape)\n",
        "# y = y[np.where(y.sum(axis=1) != 0)[0]]\n",
        "# y_new = LabelEncoder().fit_transform([''.join(str(l)) for l in y])\n",
        "# print(y_new)\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "historyl = list()\n",
        "# cross validation\n",
        "kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=0)\n",
        "#optimizer = AdamOptimizer(learning_rate=0.0001)\n",
        "#optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "for train, test in kfold.split(data, Y):\n",
        "    # x_train, x_test, Y_train, Y_test = train_test_split(data, y_train, test_size=0.8, random_state=0)\n",
        "    count += 1\n",
        "    print('Fold: {0}'.format(count))\n",
        "    print(data[train].shape, y_train[train].shape)\n",
        "    model = create_embedded_model(embedding, len(uniques), MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "    # adad = tf.train.AdadeltaOptimizer()\n",
        "    # adam = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    print('Training...')\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience)\n",
        "    mc = ModelCheckpoint('best_model'+str(count)+'.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "    # model.fit(np.reshape(data[train],(-1,data[train].shape[0],data[train].shape[1])), y_train[train], epochs=50, batch_size=batch_size, verbose=1, steps_per_epoch=20)  # 50 , steps_per_epoch=20\n",
        "    history = model.fit(data[train], y_train[train], validation_split=0.1, epochs=epochs, batch_size=batch_size, verbose=2, callbacks=[es, mc])  # 50 , steps_per_epoch=20\n",
        "    historyl.append(history)\n",
        "    # save_model(model, \"data/model\")\n",
        "    saved_model = load_model('best_model'+str(count)+'.h5')\n",
        "    # HASTA AQUÃ  OK------------------------------------------------------------\n",
        "\n",
        "    # TESTING\n",
        "    print()\n",
        "    print(\"Testing data\")\n",
        "    print(data[test].shape, y_train[test].shape)\n",
        "\n",
        "    score, acc = saved_model.evaluate(data[test], y_train[test], verbose=1)\n",
        "    print(\"acc: \", acc)\n",
        "    print(\"Accuracy: {0:.2%}\".format(acc))\n",
        "    print('Test score:', score)\n",
        "    y_predict = saved_model.predict(data[test])\n",
        "    # y_predict = np.argmax(y_predict, axis=1)\n",
        "    print(y_predict.shape)\n",
        "    labels_pred = np.argmax(np.round(y_predict),axis=1)\n",
        "    labels_test = np.argmax(y_train[test], axis=1)\n",
        "    print(labels_test)\n",
        "    print(labels_pred)\n",
        "    #print(y_train[test], np.round(y_predict))\n",
        "    accur = accuracy_score(y_train[test], np.round(y_predict))\n",
        "    # print(roc_auc_score(Y[test], y_predict, average='macro'))\n",
        "    print('Test accuracy:', accur)\n",
        "    #print(confusion_matrix(np.argmax(y_train[test],axis=1), np.round(y_predict).argmax(axis=1)))\n",
        "    b_acc = balanced_accuracy_score(labels_test, labels_pred)\n",
        "    recall = recall_score(labels_test, labels_pred, average='weighted')\n",
        "    precision = precision_score(labels_test, labels_pred, average='weighted', labels=np.unique(labels_pred))\n",
        "    f1 = f1_score(labels_test, labels_pred, average='weighted')\n",
        "    print('Test b_acc:', b_acc)\n",
        "    print('Test precision:', precision)\n",
        "    print('Test recall:', recall)\n",
        "    print('Test f1:', f1)\n",
        "    accuracy_list.append(b_acc)\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "    print(classification_report(labels_test, labels_pred))\n",
        "    # print(history.history.keys())\n",
        "    plt.plot(history.history['loss'], color='blue')\n",
        "    plt.plot(history.history['val_loss'], color='red')\n",
        "    # plt.title(str(count))\n",
        "    #plt.show()\n",
        "    # fig.savefig(str(count)+'.png', bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','validation'], loc='upper left')\n",
        "# plt.show()\n",
        "# plt.boxplot(accuracy_list)\n",
        "plt.show()\n",
        "# fig.savefig('box.png', bbox_inches='tight', pad_inches=0)\n",
        "print('avg b_accuracy precision recall f1')\n",
        "# print('avg b_accuracy {0}'.format(np.average(accuracy_list)))\n",
        "# print('avg precision {0}'.format(np.average(precision_list)))\n",
        "# print('avg recall {0}'.format(np.average(recall_list)))\n",
        "# print('avg f1 {0}'.format(np.average(f1_list)))\n",
        "print(np.average(accuracy_list))\n",
        "print(np.average(precision_list))\n",
        "print(np.average(recall_list))\n",
        "f1_final = np.average(f1_list)\n",
        "print(f1_final)\n",
        "\n",
        "fig.savefig('loss_dnn(patience='+str(patience)+', epochs='+str(epochs)+', batch_size='+str(batch_size)+', neurons= '+str(neurons)+', activation='+str(activation)+', Dropout='+str(dropout)+', fold='+str(folds)+', optimizer='+str(optimizer)+', f1=' + str(f1_final) +').png', bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "#plt.figure()\n",
        "# sys.stdout.close()"
      ],
      "metadata": {
        "id": "dw6Yn0_ArEDC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21b6d1ea-41be-4451-e1ae-263f369ebb26"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data\n",
            "(4692, 150) (4692, 2)\n",
            "Fold: 1\n",
            "(3753, 150) (3753, 2)\n",
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 150, 100)          33925200  \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 15000)             0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 16)                240016    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 34,165,250\n",
            "Trainable params: 240,050\n",
            "Non-trainable params: 33,925,200\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training...\n",
            "Epoch 1/16\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.76244, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.7263 - accuracy: 0.4836 - val_loss: 0.7624 - val_accuracy: 0.2793\n",
            "Epoch 2/16\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.76244 to 0.75369, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.7226 - accuracy: 0.4960 - val_loss: 0.7537 - val_accuracy: 0.2926\n",
            "Epoch 3/16\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.75369 to 0.74445, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.7164 - accuracy: 0.5087 - val_loss: 0.7444 - val_accuracy: 0.3138\n",
            "Epoch 4/16\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.74445 to 0.74012, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.7082 - accuracy: 0.5158 - val_loss: 0.7401 - val_accuracy: 0.3298\n",
            "Epoch 5/16\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.74012 to 0.73560, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.7092 - accuracy: 0.5150 - val_loss: 0.7356 - val_accuracy: 0.3431\n",
            "Epoch 6/16\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.73560 to 0.73059, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.7026 - accuracy: 0.5274 - val_loss: 0.7306 - val_accuracy: 0.3564\n",
            "Epoch 7/16\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.73059 to 0.72564, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.7053 - accuracy: 0.5215 - val_loss: 0.7256 - val_accuracy: 0.3697\n",
            "Epoch 8/16\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.72564 to 0.72211, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.7039 - accuracy: 0.5232 - val_loss: 0.7221 - val_accuracy: 0.3803\n",
            "Epoch 9/16\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.72211 to 0.72113, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.7019 - accuracy: 0.5078 - val_loss: 0.7211 - val_accuracy: 0.3750\n",
            "Epoch 10/16\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.72113 to 0.71885, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.6999 - accuracy: 0.5215 - val_loss: 0.7189 - val_accuracy: 0.3697\n",
            "Epoch 11/16\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.71885 to 0.71729, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.6980 - accuracy: 0.5280 - val_loss: 0.7173 - val_accuracy: 0.3750\n",
            "Epoch 12/16\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.71729 to 0.71691, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.6968 - accuracy: 0.5224 - val_loss: 0.7169 - val_accuracy: 0.3670\n",
            "Epoch 13/16\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.71691 to 0.71624, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.6944 - accuracy: 0.5404 - val_loss: 0.7162 - val_accuracy: 0.3777\n",
            "Epoch 14/16\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.71624\n",
            "27/27 - 0s - loss: 0.6927 - accuracy: 0.5360 - val_loss: 0.7163 - val_accuracy: 0.3617\n",
            "Epoch 15/16\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.71624 to 0.71489, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.6961 - accuracy: 0.5250 - val_loss: 0.7149 - val_accuracy: 0.3723\n",
            "Epoch 16/16\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.71489 to 0.71436, saving model to best_model1.h5\n",
            "27/27 - 1s - loss: 0.6953 - accuracy: 0.5304 - val_loss: 0.7144 - val_accuracy: 0.3750\n",
            "\n",
            "Testing data\n",
            "(939, 150) (939, 2)\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5186\n",
            "acc:  0.5186368227005005\n",
            "Accuracy: 51.86%\n",
            "Test score: 0.6935074925422668\n",
            "(939, 2)\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 1 0 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0\n",
            " 1 0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 0 1 1\n",
            " 1 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1\n",
            " 1 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0\n",
            " 1 1 0 0 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1\n",
            " 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 1\n",
            " 0 1 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0\n",
            " 1 0 0 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0\n",
            " 0 1 1 0 0 1 1 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1\n",
            " 1 1 1 0 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1\n",
            " 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 0\n",
            " 0 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0\n",
            " 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 0\n",
            " 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 1\n",
            " 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 0 0 1 1 0 1\n",
            " 0 1 1 1 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 1\n",
            " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0\n",
            " 0 0 1 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 1\n",
            " 0 0 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0\n",
            " 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0\n",
            " 0 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n",
            " 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0\n",
            " 1 0 0 1 0 1 1 1 0 1 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0\n",
            " 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0\n",
            " 1 0 0 0 1 1 0 0 1 1 1 1 1 1]\n",
            "Test accuracy: 0.28753993610223644\n",
            "Test b_acc: 0.5272308669418863\n",
            "Test precision: 0.5277760450494902\n",
            "Test recall: 0.5271565495207667\n",
            "Test f1: 0.5248448598919184\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.60      0.56       469\n",
            "           1       0.53      0.46      0.49       470\n",
            "\n",
            "    accuracy                           0.53       939\n",
            "   macro avg       0.53      0.53      0.52       939\n",
            "weighted avg       0.53      0.53      0.52       939\n",
            "\n",
            "Fold: 2\n",
            "(3753, 150) (3753, 2)\n",
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 150, 100)          33925200  \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 15000)             0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 16)                240016    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 34,165,250\n",
            "Trainable params: 240,050\n",
            "Non-trainable params: 33,925,200\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training...\n",
            "Epoch 1/16\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.73361, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.7340 - accuracy: 0.4960 - val_loss: 0.7336 - val_accuracy: 0.4069\n",
            "Epoch 2/16\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.73361 to 0.72891, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.7245 - accuracy: 0.4972 - val_loss: 0.7289 - val_accuracy: 0.4176\n",
            "Epoch 3/16\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.72891 to 0.72410, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.7217 - accuracy: 0.5078 - val_loss: 0.7241 - val_accuracy: 0.4282\n",
            "Epoch 4/16\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.72410 to 0.72162, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.7160 - accuracy: 0.5070 - val_loss: 0.7216 - val_accuracy: 0.4335\n",
            "Epoch 5/16\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.72162 to 0.71657, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.7153 - accuracy: 0.5040 - val_loss: 0.7166 - val_accuracy: 0.4574\n",
            "Epoch 6/16\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.71657 to 0.71422, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.7131 - accuracy: 0.4993 - val_loss: 0.7142 - val_accuracy: 0.4601\n",
            "Epoch 7/16\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.71422 to 0.71194, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.7084 - accuracy: 0.5028 - val_loss: 0.7119 - val_accuracy: 0.4681\n",
            "Epoch 8/16\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.71194 to 0.71020, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.7077 - accuracy: 0.5158 - val_loss: 0.7102 - val_accuracy: 0.4734\n",
            "Epoch 9/16\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.71020 to 0.70832, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.7006 - accuracy: 0.5327 - val_loss: 0.7083 - val_accuracy: 0.4787\n",
            "Epoch 10/16\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.70832 to 0.70642, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.7056 - accuracy: 0.5117 - val_loss: 0.7064 - val_accuracy: 0.4787\n",
            "Epoch 11/16\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.70642 to 0.70639, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.7049 - accuracy: 0.5235 - val_loss: 0.7064 - val_accuracy: 0.4787\n",
            "Epoch 12/16\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.70639 to 0.70439, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.7017 - accuracy: 0.5209 - val_loss: 0.7044 - val_accuracy: 0.4787\n",
            "Epoch 13/16\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.70439 to 0.70404, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.6983 - accuracy: 0.5336 - val_loss: 0.7040 - val_accuracy: 0.4814\n",
            "Epoch 14/16\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.70404 to 0.70308, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.7023 - accuracy: 0.5179 - val_loss: 0.7031 - val_accuracy: 0.4840\n",
            "Epoch 15/16\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.70308 to 0.70246, saving model to best_model2.h5\n",
            "27/27 - 1s - loss: 0.6978 - accuracy: 0.5345 - val_loss: 0.7025 - val_accuracy: 0.4814\n",
            "Epoch 16/16\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.70246\n",
            "27/27 - 0s - loss: 0.6978 - accuracy: 0.5170 - val_loss: 0.7028 - val_accuracy: 0.4734\n",
            "\n",
            "Testing data\n",
            "(939, 150) (939, 2)\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5048\n",
            "acc:  0.504792332649231\n",
            "Accuracy: 50.48%\n",
            "Test score: 0.6956383585929871\n",
            "(939, 2)\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1\n",
            " 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1\n",
            " 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1\n",
            " 0 0 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 0 0 1 1\n",
            " 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 1\n",
            " 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0\n",
            " 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 0 1\n",
            " 0 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0 0 1 0 0 1 0 1\n",
            " 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 0 0 0 1 0\n",
            " 0 0 1 1 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 1 1\n",
            " 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 0 1\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1\n",
            " 1 0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1\n",
            " 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1\n",
            " 0 1 0 1 1 1 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 0 1 0\n",
            " 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0\n",
            " 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 1\n",
            " 1 0 1 0 0 1 1 0 0 1 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1\n",
            " 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 1 1 1 1 0\n",
            " 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1\n",
            " 0 1 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
            " 0 1 1 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 1\n",
            " 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
            " 0 0 1 0 0 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
            " 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0\n",
            " 1 1 0 1 0 0 1 0 1 1 0 1 0 0]\n",
            "Test accuracy: 0.3588924387646432\n",
            "Test b_acc: 0.5217960350224561\n",
            "Test precision: 0.5218935697106233\n",
            "Test recall: 0.5218317358892439\n",
            "Test f1: 0.521293136441309\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.56      0.54       470\n",
            "           1       0.52      0.49      0.50       469\n",
            "\n",
            "    accuracy                           0.52       939\n",
            "   macro avg       0.52      0.52      0.52       939\n",
            "weighted avg       0.52      0.52      0.52       939\n",
            "\n",
            "Fold: 3\n",
            "(3754, 150) (3754, 2)\n",
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 150, 100)          33925200  \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 15000)             0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 16)                240016    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 34,165,250\n",
            "Trainable params: 240,050\n",
            "Non-trainable params: 33,925,200\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training...\n",
            "Epoch 1/16\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.62657, saving model to best_model3.h5\n",
            "27/27 - 1s - loss: 0.7317 - accuracy: 0.4802 - val_loss: 0.6266 - val_accuracy: 0.8404\n",
            "Epoch 2/16\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.62657\n",
            "27/27 - 0s - loss: 0.7326 - accuracy: 0.4704 - val_loss: 0.6346 - val_accuracy: 0.8245\n",
            "Epoch 3/16\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.62657\n",
            "27/27 - 0s - loss: 0.7251 - accuracy: 0.4772 - val_loss: 0.6399 - val_accuracy: 0.8218\n",
            "Epoch 4/16\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.62657\n",
            "27/27 - 0s - loss: 0.7187 - accuracy: 0.4831 - val_loss: 0.6443 - val_accuracy: 0.8085\n",
            "Epoch 5/16\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.62657\n",
            "27/27 - 0s - loss: 0.7165 - accuracy: 0.4843 - val_loss: 0.6493 - val_accuracy: 0.7846\n",
            "Epoch 6/16\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.62657\n",
            "27/27 - 0s - loss: 0.7169 - accuracy: 0.4769 - val_loss: 0.6535 - val_accuracy: 0.7633\n",
            "Epoch 7/16\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.62657\n",
            "27/27 - 0s - loss: 0.7142 - accuracy: 0.4852 - val_loss: 0.6566 - val_accuracy: 0.7527\n",
            "Epoch 8/16\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.62657\n",
            "27/27 - 0s - loss: 0.7097 - accuracy: 0.4970 - val_loss: 0.6579 - val_accuracy: 0.7500\n",
            "Epoch 9/16\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.62657\n",
            "27/27 - 0s - loss: 0.7076 - accuracy: 0.4896 - val_loss: 0.6602 - val_accuracy: 0.7473\n",
            "Epoch 10/16\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.62657\n",
            "27/27 - 0s - loss: 0.7078 - accuracy: 0.4890 - val_loss: 0.6623 - val_accuracy: 0.7447\n",
            "Epoch 11/16\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.62657\n",
            "27/27 - 0s - loss: 0.7069 - accuracy: 0.4923 - val_loss: 0.6643 - val_accuracy: 0.7261\n",
            "Epoch 00011: early stopping\n",
            "\n",
            "Testing data\n",
            "(938, 150) (938, 2)\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7038 - accuracy: 0.4979\n",
            "acc:  0.49786779284477234\n",
            "Accuracy: 49.79%\n",
            "Test score: 0.7038047313690186\n",
            "(938, 2)\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Test accuracy: 0.2835820895522388\n",
            "Test b_acc: 0.4989339019189766\n",
            "Test precision: 0.46401718582169715\n",
            "Test recall: 0.4989339019189765\n",
            "Test f1: 0.3384453781512605\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.99      0.66       469\n",
            "           1       0.43      0.01      0.01       469\n",
            "\n",
            "    accuracy                           0.50       938\n",
            "   macro avg       0.46      0.50      0.34       938\n",
            "weighted avg       0.46      0.50      0.34       938\n",
            "\n",
            "Fold: 4\n",
            "(3754, 150) (3754, 2)\n",
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_19 (InputLayer)        [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 150, 100)          33925200  \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 15000)             0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 16)                240016    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 34,165,250\n",
            "Trainable params: 240,050\n",
            "Non-trainable params: 33,925,200\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training...\n",
            "Epoch 1/16\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.59821, saving model to best_model4.h5\n",
            "27/27 - 1s - loss: 0.7391 - accuracy: 0.4852 - val_loss: 0.5982 - val_accuracy: 0.8298\n",
            "Epoch 2/16\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.59821\n",
            "27/27 - 0s - loss: 0.7281 - accuracy: 0.4805 - val_loss: 0.6154 - val_accuracy: 0.7686\n",
            "Epoch 3/16\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.59821\n",
            "27/27 - 0s - loss: 0.7239 - accuracy: 0.4890 - val_loss: 0.6294 - val_accuracy: 0.7340\n",
            "Epoch 4/16\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.59821\n",
            "27/27 - 0s - loss: 0.7193 - accuracy: 0.4935 - val_loss: 0.6410 - val_accuracy: 0.6941\n",
            "Epoch 5/16\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.59821\n",
            "27/27 - 0s - loss: 0.7130 - accuracy: 0.5038 - val_loss: 0.6522 - val_accuracy: 0.6569\n",
            "Epoch 6/16\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.59821\n",
            "27/27 - 0s - loss: 0.7128 - accuracy: 0.4938 - val_loss: 0.6613 - val_accuracy: 0.6170\n",
            "Epoch 7/16\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.59821\n",
            "27/27 - 0s - loss: 0.7090 - accuracy: 0.4970 - val_loss: 0.6661 - val_accuracy: 0.5851\n",
            "Epoch 8/16\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.59821\n",
            "27/27 - 0s - loss: 0.7049 - accuracy: 0.5083 - val_loss: 0.6727 - val_accuracy: 0.5638\n",
            "Epoch 9/16\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.59821\n",
            "27/27 - 0s - loss: 0.7089 - accuracy: 0.4973 - val_loss: 0.6791 - val_accuracy: 0.5426\n",
            "Epoch 10/16\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.59821\n",
            "27/27 - 0s - loss: 0.7017 - accuracy: 0.5172 - val_loss: 0.6849 - val_accuracy: 0.5239\n",
            "Epoch 11/16\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.59821\n",
            "27/27 - 0s - loss: 0.7005 - accuracy: 0.5222 - val_loss: 0.6872 - val_accuracy: 0.5106\n",
            "Epoch 00011: early stopping\n",
            "\n",
            "Testing data\n",
            "(938, 150) (938, 2)\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.5256\n",
            "acc:  0.5255863666534424\n",
            "Accuracy: 52.56%\n",
            "Test score: 0.6977209448814392\n",
            "(938, 2)\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "Test accuracy: 0.3006396588486141\n",
            "Test b_acc: 0.5031982942430704\n",
            "Test precision: 0.5235560020090406\n",
            "Test recall: 0.5031982942430704\n",
            "Test f1: 0.36627869888712977\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.97      0.66       469\n",
            "           1       0.55      0.04      0.07       469\n",
            "\n",
            "    accuracy                           0.50       938\n",
            "   macro avg       0.52      0.50      0.37       938\n",
            "weighted avg       0.52      0.50      0.37       938\n",
            "\n",
            "Fold: 5\n",
            "(3754, 150) (3754, 2)\n",
            "Model: \"model_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_20 (InputLayer)        [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 150, 100)          33925200  \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 15000)             0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 16)                240016    \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 34,165,250\n",
            "Trainable params: 240,050\n",
            "Non-trainable params: 33,925,200\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training...\n",
            "Epoch 1/16\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.73419, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.7152 - accuracy: 0.5118 - val_loss: 0.7342 - val_accuracy: 0.3989\n",
            "Epoch 2/16\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.73419 to 0.72844, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.7111 - accuracy: 0.5237 - val_loss: 0.7284 - val_accuracy: 0.4229\n",
            "Epoch 3/16\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.72844 to 0.72261, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.7068 - accuracy: 0.5406 - val_loss: 0.7226 - val_accuracy: 0.4521\n",
            "Epoch 4/16\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.72261 to 0.72011, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.7092 - accuracy: 0.5222 - val_loss: 0.7201 - val_accuracy: 0.4495\n",
            "Epoch 5/16\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.72011 to 0.71744, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.7027 - accuracy: 0.5281 - val_loss: 0.7174 - val_accuracy: 0.4601\n",
            "Epoch 6/16\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.71744 to 0.71586, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.7018 - accuracy: 0.5263 - val_loss: 0.7159 - val_accuracy: 0.4601\n",
            "Epoch 7/16\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.71586 to 0.71552, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.6964 - accuracy: 0.5370 - val_loss: 0.7155 - val_accuracy: 0.4628\n",
            "Epoch 8/16\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.71552 to 0.71248, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.7012 - accuracy: 0.5391 - val_loss: 0.7125 - val_accuracy: 0.4707\n",
            "Epoch 9/16\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.71248 to 0.71109, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.6982 - accuracy: 0.5409 - val_loss: 0.7111 - val_accuracy: 0.4761\n",
            "Epoch 10/16\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.71109\n",
            "27/27 - 0s - loss: 0.7028 - accuracy: 0.5349 - val_loss: 0.7112 - val_accuracy: 0.4787\n",
            "Epoch 11/16\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.71109 to 0.70896, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.6967 - accuracy: 0.5370 - val_loss: 0.7090 - val_accuracy: 0.4867\n",
            "Epoch 12/16\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.70896\n",
            "27/27 - 0s - loss: 0.6976 - accuracy: 0.5426 - val_loss: 0.7092 - val_accuracy: 0.4814\n",
            "Epoch 13/16\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.70896 to 0.70727, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.6914 - accuracy: 0.5527 - val_loss: 0.7073 - val_accuracy: 0.4787\n",
            "Epoch 14/16\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.70727 to 0.70622, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.6953 - accuracy: 0.5509 - val_loss: 0.7062 - val_accuracy: 0.4814\n",
            "Epoch 15/16\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.70622 to 0.70416, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.6924 - accuracy: 0.5542 - val_loss: 0.7042 - val_accuracy: 0.4867\n",
            "Epoch 16/16\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.70416 to 0.70286, saving model to best_model5.h5\n",
            "27/27 - 1s - loss: 0.6893 - accuracy: 0.5571 - val_loss: 0.7029 - val_accuracy: 0.4920\n",
            "\n",
            "Testing data\n",
            "(938, 150) (938, 2)\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5235\n",
            "acc:  0.5234541296958923\n",
            "Accuracy: 52.35%\n",
            "Test score: 0.6950212717056274\n",
            "(938, 2)\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0\n",
            " 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1\n",
            " 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1\n",
            " 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 0 1 0 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0\n",
            " 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 1 1\n",
            " 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 1\n",
            " 1 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0 1 1\n",
            " 1 1 1 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 0 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1\n",
            " 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 0\n",
            " 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 1 0 1\n",
            " 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 0 1\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1 0 0 0\n",
            " 0 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 0 0 0\n",
            " 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0\n",
            " 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1 0\n",
            " 1 0 1 1 1 0 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0\n",
            " 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0\n",
            " 0 0 0 0 1 0 1 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 1\n",
            " 1 0 0 0 1 1 0 1 1 0 0 1 0]\n",
            "Test accuracy: 0.44243070362473347\n",
            "Test b_acc: 0.5319829424307037\n",
            "Test precision: 0.5339540136684814\n",
            "Test recall: 0.5319829424307037\n",
            "Test f1: 0.525090678430355\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.41      0.47       469\n",
            "           1       0.53      0.65      0.58       469\n",
            "\n",
            "    accuracy                           0.53       938\n",
            "   macro avg       0.53      0.53      0.53       938\n",
            "weighted avg       0.53      0.53      0.53       938\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg b_accuracy precision recall f1\n",
            "0.5166284081114185\n",
            "0.5142393632518665\n",
            "0.5166206848005522\n",
            "0.4551905503603946\n"
          ]
        }
      ]
    }
  ]
}
