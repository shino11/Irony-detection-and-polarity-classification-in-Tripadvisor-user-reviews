{  
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DmLaPD4AvIWhU2bFjbFIwlbADma2xEeK",
      "authorship_tag": "ABX9TyM3RZJEbFGkennFk6axGV8x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shino11/Irony-detection-and-polarity-classification-in-Tripadvisor-user-reviews./blob/main/sgd_lstm1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UyD97985NGRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3080184c-f3c6-4c76-a8a3-b86bedf162d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "Tlq8Xay486KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow==2.0\n",
        "!pip install -U numpy==1.19.5\n",
        "!pip install h5py==2.10.0\n",
        "\n",
        "#!pip uninstall tensorflow\n",
        "#!pip install tensorflow\n",
        "#!pip uninstall numpy\n",
        "#!pip install numpy\n",
        "#!apt-get install python3.7\n",
        "\n",
        "#import sys\n",
        "#import tensorflow as tf\n",
        "\n",
        "#tf.__version__\n",
        "#!python3 ‐‐version\n",
        "#print(sys.version)\n",
        "\n",
        "#!pip show numpy tensorflow\n"
      ],
      "metadata": {
        "id": "-I_Vp5McH_Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-03T11:45:44.132578Z",
          "start_time": "2021-04-03T11:45:44.115562Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTpzLd6dvB6Q",
        "outputId": "7158f6dc-0828-4584-c4ac-4ef7e4705da3"
      },
      "source": [
        "# !wget https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
        "!unzip glove.42B.300d.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.42B.300d.zip\n",
            "  inflating: glove.42B.300d.txt      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O3MJivi6H2FG",
        "outputId": "c2962958-6537-4409-c426-82f51a2386d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Corpus  Label             ID  \\\n",
            "0    GEN      1  GEN_sarc_0000   \n",
            "1    GEN      1  GEN_sarc_0001   \n",
            "2    GEN      1  GEN_sarc_0002   \n",
            "3    GEN      1  GEN_sarc_0003   \n",
            "4    GEN      1  GEN_sarc_0004   \n",
            "\n",
            "                                          Quote Text  \\\n",
            "0  First off, That's grade A USDA approved Libera...   \n",
            "1  watch it. Now you're using my lines. Poet has ...   \n",
            "2  Because it will encourage teens to engage in r...   \n",
            "3  Obviously you missed the point. So sorry the t...   \n",
            "4  This is pure paranoia. What evidence do you ha...   \n",
            "\n",
            "                                       Response Text  \n",
            "0  Therefore you accept that the Republican party...  \n",
            "1  More chattering from the peanut gallery? Haven...  \n",
            "2  Yep, suppressing natural behavior is always th...  \n",
            "3  I guess we all missed your point Justine, what...  \n",
            "4  Evidence, I dont need no sticking evidence. Th...  \n",
            "23460\n",
            "(4692, 5)\n",
            "4692\n",
            "4692\n",
            "total words embeddings is  1917494 1303086\n",
            "[[18647   122  6888 ...     0     0     0]\n",
            " [  149 42453   527 ...     0     0     0]\n",
            " [24005 17270  1617 ...     0     0     0]\n",
            " ...\n",
            " [  204    85   163 ...     0     0     0]\n",
            " [  264  1204  5602 ...     0     0     0]\n",
            " [  281   419   183 ...     0     0     0]]\n",
            "[0 1]\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "Training data\n",
            "(4692, 150) (4692, 2)\n",
            "(3753, 150) (3753, 2)\n",
            "Fold: 1\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 150, 300)          390926100 \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 16)                20288     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 390,946,422\n",
            "Trainable params: 20,322\n",
            "Non-trainable params: 390,926,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training...\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.64199, saving model to best_model_lstm11.h5\n",
            "27/27 - 16s - loss: 0.6930 - accuracy: 0.5674 - val_loss: 0.6420 - val_accuracy: 0.5000 - 16s/epoch - 602ms/step\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.64199\n",
            "27/27 - 0s - loss: 0.6918 - accuracy: 0.5686 - val_loss: 0.6443 - val_accuracy: 0.4894 - 343ms/epoch - 13ms/step\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.64199\n",
            "27/27 - 0s - loss: 0.6899 - accuracy: 0.5736 - val_loss: 0.6471 - val_accuracy: 0.4734 - 277ms/epoch - 10ms/step\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.64199\n",
            "27/27 - 0s - loss: 0.6894 - accuracy: 0.5694 - val_loss: 0.6443 - val_accuracy: 0.4707 - 268ms/epoch - 10ms/step\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.64199\n",
            "27/27 - 0s - loss: 0.6874 - accuracy: 0.5686 - val_loss: 0.6491 - val_accuracy: 0.4654 - 267ms/epoch - 10ms/step\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.64199\n",
            "27/27 - 0s - loss: 0.6865 - accuracy: 0.5724 - val_loss: 0.6500 - val_accuracy: 0.4681 - 279ms/epoch - 10ms/step\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.64199\n",
            "27/27 - 0s - loss: 0.6847 - accuracy: 0.5739 - val_loss: 0.6523 - val_accuracy: 0.4707 - 282ms/epoch - 10ms/step\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.64199\n",
            "27/27 - 0s - loss: 0.6825 - accuracy: 0.5754 - val_loss: 0.6565 - val_accuracy: 0.4814 - 268ms/epoch - 10ms/step\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.64199\n",
            "27/27 - 0s - loss: 0.6815 - accuracy: 0.5721 - val_loss: 0.6627 - val_accuracy: 0.4814 - 270ms/epoch - 10ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.64199\n",
            "27/27 - 0s - loss: 0.6792 - accuracy: 0.5786 - val_loss: 0.6698 - val_accuracy: 0.4920 - 271ms/epoch - 10ms/step\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.64199\n",
            "27/27 - 0s - loss: 0.6782 - accuracy: 0.5774 - val_loss: 0.6714 - val_accuracy: 0.5053 - 278ms/epoch - 10ms/step\n",
            "Epoch 00011: early stopping\n",
            "\n",
            "Testing data\n",
            "(939, 150) (939, 2)\n",
            "30/30 [==============================] - 1s 6ms/step - loss: 0.6851 - accuracy: 0.5719\n",
            "acc:  0.5718849897384644\n",
            "Accuracy: 57.19%\n",
            "Test score: 0.6851385235786438\n",
            "(939, 2)\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1\n",
            " 0 0 1 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1\n",
            " 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 0 0 1 1 1 1 0 0\n",
            " 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1\n",
            " 0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1\n",
            " 0 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1\n",
            " 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 0 1 0\n",
            " 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 0 0 0\n",
            " 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1\n",
            " 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
            " 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1\n",
            " 0 0 0 0 1 0 0 0 1 1 1 0 1 1]\n",
            "Test accuracy: 0.5537806176783813\n",
            "Test b_acc: 0.573773987206823\n",
            "Test precision: 0.5927362924099863\n",
            "Test recall: 0.5740149094781682\n",
            "Test f1: 0.5510152840242878\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
            "(3753, 150) (3753, 2)\n",
            "Fold: 2\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 150, 300)          390926100 \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 16)                20288     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 390,946,422\n",
            "Trainable params: 20,322\n",
            "Non-trainable params: 390,926,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training...\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.73650, saving model to best_model_lstm12.h5\n",
            "27/27 - 10s - loss: 0.6971 - accuracy: 0.5372 - val_loss: 0.7365 - val_accuracy: 0.1330 - 10s/epoch - 355ms/step\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.73650 to 0.71475, saving model to best_model_lstm12.h5\n",
            "27/27 - 8s - loss: 0.6942 - accuracy: 0.5463 - val_loss: 0.7147 - val_accuracy: 0.1835 - 8s/epoch - 290ms/step\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.71475 to 0.70791, saving model to best_model_lstm12.h5\n",
            "27/27 - 8s - loss: 0.6908 - accuracy: 0.5594 - val_loss: 0.7079 - val_accuracy: 0.2633 - 8s/epoch - 299ms/step\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.70791 to 0.70248, saving model to best_model_lstm12.h5\n",
            "27/27 - 8s - loss: 0.6897 - accuracy: 0.5614 - val_loss: 0.7025 - val_accuracy: 0.3431 - 8s/epoch - 303ms/step\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.70248 to 0.70234, saving model to best_model_lstm12.h5\n",
            "27/27 - 8s - loss: 0.6885 - accuracy: 0.5683 - val_loss: 0.7023 - val_accuracy: 0.3511 - 8s/epoch - 302ms/step\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.70234\n",
            "27/27 - 0s - loss: 0.6870 - accuracy: 0.5686 - val_loss: 0.7041 - val_accuracy: 0.3564 - 314ms/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.70234\n",
            "27/27 - 0s - loss: 0.6857 - accuracy: 0.5727 - val_loss: 0.7026 - val_accuracy: 0.3723 - 281ms/epoch - 10ms/step\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.70234\n",
            "27/27 - 0s - loss: 0.6848 - accuracy: 0.5742 - val_loss: 0.7051 - val_accuracy: 0.3697 - 287ms/epoch - 11ms/step\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.70234\n",
            "27/27 - 0s - loss: 0.6843 - accuracy: 0.5694 - val_loss: 0.7115 - val_accuracy: 0.3697 - 273ms/epoch - 10ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.70234\n",
            "27/27 - 0s - loss: 0.6826 - accuracy: 0.5768 - val_loss: 0.7108 - val_accuracy: 0.3777 - 284ms/epoch - 11ms/step\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.70234\n",
            "27/27 - 0s - loss: 0.6817 - accuracy: 0.5736 - val_loss: 0.7185 - val_accuracy: 0.3697 - 273ms/epoch - 10ms/step\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.70234\n",
            "27/27 - 0s - loss: 0.6816 - accuracy: 0.5706 - val_loss: 0.7242 - val_accuracy: 0.3697 - 281ms/epoch - 10ms/step\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.70234\n",
            "27/27 - 0s - loss: 0.6798 - accuracy: 0.5768 - val_loss: 0.7297 - val_accuracy: 0.3723 - 273ms/epoch - 10ms/step\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.70234\n",
            "27/27 - 0s - loss: 0.6789 - accuracy: 0.5792 - val_loss: 0.7326 - val_accuracy: 0.3723 - 272ms/epoch - 10ms/step\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.70234\n",
            "27/27 - 0s - loss: 0.6788 - accuracy: 0.5792 - val_loss: 0.7384 - val_accuracy: 0.3617 - 280ms/epoch - 10ms/step\n",
            "Epoch 00015: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing data\n",
            "(939, 150) (939, 2)\n",
            "30/30 [==============================] - 1s 6ms/step - loss: 0.6889 - accuracy: 0.5463\n",
            "acc:  0.5463258624076843\n",
            "Accuracy: 54.63%\n",
            "Test score: 0.6889452934265137\n",
            "(939, 2)\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0\n",
            " 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
            " 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1\n",
            " 1 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
            " 0 1 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1\n",
            " 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1\n",
            " 0 0 0 0 1 0 0 1 1 1 0 1 0 0]\n",
            "Test accuracy: 0.5186368477103301\n",
            "Test b_acc: 0.5584176382525065\n",
            "Test precision: 0.617286839724612\n",
            "Test recall: 0.5580404685835996\n",
            "Test f1: 0.4947073928162647\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
            "(3754, 150) (3754, 2)\n",
            "Fold: 3\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 150, 300)          390926100 \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 16)                20288     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 390,946,422\n",
            "Trainable params: 20,322\n",
            "Non-trainable params: 390,926,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training...\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.65456, saving model to best_model_lstm13.h5\n",
            "27/27 - 10s - loss: 0.6912 - accuracy: 0.5613 - val_loss: 0.6546 - val_accuracy: 0.4441 - 10s/epoch - 362ms/step\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.65456\n",
            "27/27 - 0s - loss: 0.6887 - accuracy: 0.5699 - val_loss: 0.6671 - val_accuracy: 0.4335 - 346ms/epoch - 13ms/step\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.65456\n",
            "27/27 - 0s - loss: 0.6868 - accuracy: 0.5743 - val_loss: 0.6679 - val_accuracy: 0.4335 - 276ms/epoch - 10ms/step\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.65456\n",
            "27/27 - 0s - loss: 0.6850 - accuracy: 0.5737 - val_loss: 0.6756 - val_accuracy: 0.4309 - 295ms/epoch - 11ms/step\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.65456\n",
            "27/27 - 0s - loss: 0.6833 - accuracy: 0.5749 - val_loss: 0.6786 - val_accuracy: 0.4282 - 295ms/epoch - 11ms/step\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.65456\n",
            "27/27 - 0s - loss: 0.6817 - accuracy: 0.5758 - val_loss: 0.6871 - val_accuracy: 0.4255 - 282ms/epoch - 10ms/step\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.65456\n",
            "27/27 - 0s - loss: 0.6810 - accuracy: 0.5776 - val_loss: 0.6911 - val_accuracy: 0.4202 - 274ms/epoch - 10ms/step\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.65456\n",
            "27/27 - 0s - loss: 0.6803 - accuracy: 0.5767 - val_loss: 0.6937 - val_accuracy: 0.4255 - 284ms/epoch - 11ms/step\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.65456\n",
            "27/27 - 0s - loss: 0.6786 - accuracy: 0.5793 - val_loss: 0.6983 - val_accuracy: 0.4202 - 279ms/epoch - 10ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.65456\n",
            "27/27 - 0s - loss: 0.6778 - accuracy: 0.5811 - val_loss: 0.7012 - val_accuracy: 0.4229 - 289ms/epoch - 11ms/step\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.65456\n",
            "27/27 - 0s - loss: 0.6780 - accuracy: 0.5811 - val_loss: 0.7040 - val_accuracy: 0.4176 - 273ms/epoch - 10ms/step\n",
            "Epoch 00011: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing data\n",
            "(938, 150) (938, 2)\n",
            "30/30 [==============================] - 1s 8ms/step - loss: 0.6850 - accuracy: 0.5533\n",
            "acc:  0.55330491065979\n",
            "Accuracy: 55.33%\n",
            "Test score: 0.684986412525177\n",
            "(938, 2)\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1\n",
            " 0 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0\n",
            " 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0\n",
            " 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1\n",
            " 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1\n",
            " 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1\n",
            " 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 0 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1\n",
            " 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 1\n",
            " 0 0 1 0 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0\n",
            " 0 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1\n",
            " 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1\n",
            " 0 0 1 1 1 1 1 0 0 0 0 1 1]\n",
            "Test accuracy: 0.5458422174840085\n",
            "Test b_acc: 0.5575692963752665\n",
            "Test precision: 0.5870716211012706\n",
            "Test recall: 0.5575692963752665\n",
            "Test f1: 0.5166239297666131\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
            "(3754, 150) (3754, 2)\n",
            "Fold: 4\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 150, 300)          390926100 \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 16)                20288     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 390,946,422\n",
            "Trainable params: 20,322\n",
            "Non-trainable params: 390,926,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training...\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.66702, saving model to best_model_lstm14.h5\n",
            "27/27 - 10s - loss: 0.6928 - accuracy: 0.5660 - val_loss: 0.6670 - val_accuracy: 0.3883 - 10s/epoch - 365ms/step\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.66702\n",
            "27/27 - 0s - loss: 0.6882 - accuracy: 0.5722 - val_loss: 0.6691 - val_accuracy: 0.3963 - 400ms/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.66702\n",
            "27/27 - 0s - loss: 0.6855 - accuracy: 0.5784 - val_loss: 0.6676 - val_accuracy: 0.3936 - 273ms/epoch - 10ms/step\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.66702\n",
            "27/27 - 0s - loss: 0.6844 - accuracy: 0.5764 - val_loss: 0.6837 - val_accuracy: 0.3803 - 277ms/epoch - 10ms/step\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.66702\n",
            "27/27 - 0s - loss: 0.6826 - accuracy: 0.5767 - val_loss: 0.6880 - val_accuracy: 0.3830 - 280ms/epoch - 10ms/step\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.66702\n",
            "27/27 - 0s - loss: 0.6826 - accuracy: 0.5761 - val_loss: 0.6935 - val_accuracy: 0.3777 - 292ms/epoch - 11ms/step\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.66702\n",
            "27/27 - 0s - loss: 0.6802 - accuracy: 0.5793 - val_loss: 0.6941 - val_accuracy: 0.3830 - 265ms/epoch - 10ms/step\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.66702\n",
            "27/27 - 0s - loss: 0.6794 - accuracy: 0.5814 - val_loss: 0.6966 - val_accuracy: 0.3830 - 270ms/epoch - 10ms/step\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.66702\n",
            "27/27 - 0s - loss: 0.6785 - accuracy: 0.5832 - val_loss: 0.7067 - val_accuracy: 0.3617 - 293ms/epoch - 11ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.66702\n",
            "27/27 - 0s - loss: 0.6773 - accuracy: 0.5808 - val_loss: 0.7092 - val_accuracy: 0.3617 - 276ms/epoch - 10ms/step\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.66702\n",
            "27/27 - 0s - loss: 0.6781 - accuracy: 0.5811 - val_loss: 0.7089 - val_accuracy: 0.3644 - 283ms/epoch - 10ms/step\n",
            "Epoch 00011: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing data\n",
            "(938, 150) (938, 2)\n",
            "30/30 [==============================] - 1s 6ms/step - loss: 0.6891 - accuracy: 0.5501\n",
            "acc:  0.5501065850257874\n",
            "Accuracy: 55.01%\n",
            "Test score: 0.6891373991966248\n",
            "(938, 2)\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
            " 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1\n",
            " 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1\n",
            " 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0\n",
            " 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 1\n",
            " 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 1 0\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 0 0 1 0 0\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1\n",
            " 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0\n",
            " 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0\n",
            " 0 1 1 0 1 1 1 1 1 1 0 1 1]\n",
            "Test accuracy: 0.5277185501066098\n",
            "Test b_acc: 0.5458422174840085\n",
            "Test precision: 0.5706736194341064\n",
            "Test recall: 0.5458422174840085\n",
            "Test f1: 0.5021082535885167\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
            "(3754, 150) (3754, 2)\n",
            "Fold: 5\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 150, 300)          390926100 \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 16)                20288     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 390,946,422\n",
            "Trainable params: 20,322\n",
            "Non-trainable params: 390,926,100\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training...\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.67746, saving model to best_model_lstm15.h5\n",
            "27/27 - 10s - loss: 0.6923 - accuracy: 0.5634 - val_loss: 0.6775 - val_accuracy: 0.4202 - 10s/epoch - 361ms/step\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.67746 to 0.66938, saving model to best_model_lstm15.h5\n",
            "27/27 - 8s - loss: 0.6877 - accuracy: 0.5758 - val_loss: 0.6694 - val_accuracy: 0.4309 - 8s/epoch - 302ms/step\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.66938\n",
            "27/27 - 0s - loss: 0.6863 - accuracy: 0.5761 - val_loss: 0.6738 - val_accuracy: 0.4255 - 431ms/epoch - 16ms/step\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.66938\n",
            "27/27 - 0s - loss: 0.6841 - accuracy: 0.5749 - val_loss: 0.6768 - val_accuracy: 0.4202 - 284ms/epoch - 11ms/step\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.66938\n",
            "27/27 - 0s - loss: 0.6837 - accuracy: 0.5758 - val_loss: 0.6814 - val_accuracy: 0.4149 - 287ms/epoch - 11ms/step\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.66938\n",
            "27/27 - 0s - loss: 0.6820 - accuracy: 0.5782 - val_loss: 0.6878 - val_accuracy: 0.3989 - 271ms/epoch - 10ms/step\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.66938\n",
            "27/27 - 0s - loss: 0.6813 - accuracy: 0.5782 - val_loss: 0.6928 - val_accuracy: 0.3963 - 272ms/epoch - 10ms/step\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.66938\n",
            "27/27 - 0s - loss: 0.6796 - accuracy: 0.5787 - val_loss: 0.6930 - val_accuracy: 0.3989 - 273ms/epoch - 10ms/step\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.66938\n",
            "27/27 - 0s - loss: 0.6786 - accuracy: 0.5853 - val_loss: 0.7019 - val_accuracy: 0.3910 - 271ms/epoch - 10ms/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.66938\n",
            "27/27 - 0s - loss: 0.6779 - accuracy: 0.5835 - val_loss: 0.7099 - val_accuracy: 0.3777 - 273ms/epoch - 10ms/step\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.66938\n",
            "27/27 - 0s - loss: 0.6770 - accuracy: 0.5864 - val_loss: 0.7126 - val_accuracy: 0.3750 - 271ms/epoch - 10ms/step\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.66938\n",
            "27/27 - 0s - loss: 0.6760 - accuracy: 0.5864 - val_loss: 0.7187 - val_accuracy: 0.3697 - 264ms/epoch - 10ms/step\n",
            "Epoch 00012: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing data\n",
            "(938, 150) (938, 2)\n",
            "30/30 [==============================] - 1s 6ms/step - loss: 0.6870 - accuracy: 0.5544\n",
            "acc:  0.5543709993362427\n",
            "Accuracy: 55.44%\n",
            "Test score: 0.686988353729248\n",
            "(938, 2)\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 0 1 1\n",
            " 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1\n",
            " 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1\n",
            " 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 1\n",
            " 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 0\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1\n",
            " 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1\n",
            " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1\n",
            " 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0\n",
            " 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1\n",
            " 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1\n",
            " 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 0\n",
            " 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1\n",
            " 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1\n",
            " 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1\n",
            " 0 0 0 1 1 1 0 1 0 0 1 1 1]\n",
            "Test accuracy: 0.5213219616204691\n",
            "Test b_acc: 0.5575692963752665\n",
            "Test precision: 0.5828296703296704\n",
            "Test recall: 0.5575692963752665\n",
            "Test f1: 0.5210534928386258\n",
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg b_accuracy precision recall f1\n",
            "0.5586344871387742\n",
            "0.5901196085999291\n",
            "0.5586072376592619\n",
            "0.5171016706068616\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "from builtins import print\n",
        "import numpy as np\n",
        "#import keras\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "#from keras import Model\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#from tensorflow.core.protobuf import rewriter_config_pb2\n",
        "import os\n",
        "# from keras.engine.saving import model_from_json\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Flatten, Lambda\n",
        "# from keras.layers import LSTM, Input\n",
        "# from keras.layers import Dense, Embedding, Reshape\n",
        "# from keras.layers.wrappers import TimeDistributed\n",
        "# from keras.preprocessing.text import Tokenizer\n",
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "#from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score, balanced_accuracy_score, confusion_matrix\n",
        "#from statsmodels.sandbox.distributions.examples.ex_mvelliptical import fig\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.python.keras.layers.core import Dropout, RepeatVector\n",
        "from tensorflow.keras.layers import LSTM, Reshape\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "#from tensorflow.python.keras.engine.saving import model_from_json\n",
        "from tensorflow.python.training.adam import AdamOptimizer\n",
        "from tensorflow.keras import Input\n",
        "#from tensorflow_core.python.keras.layers import concatenate, Concatenate, Bidirectional\n",
        "#import matplotlib\n",
        "#matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow_addons as tfa\n",
        "\n",
        "#class HLSTM:\n",
        "\n",
        "#with tf.device('/gpu:0'):\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.python.keras.models import load_model\n",
        "\n",
        "EMBEDDING_DIM = 300\n",
        "# MAX_NB_WORDS = 100000\n",
        "text = []\n",
        "labels = []\n",
        "\n",
        "learning_rate = 0.0001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "# optimizer = 'Adadelta'  \n",
        "#optimizer = 'Adam'\n",
        "dropout = 0.5\n",
        "neurons = 16\n",
        "patience = 10\n",
        "epochs = 20\n",
        "batch_size = 128\n",
        "folds = 5\n",
        "\n",
        "\n",
        "def save_model(model, filename):\n",
        "    model_json = model.to_json()\n",
        "    with open(filename + '.model', \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "        json_file.close();\n",
        "    model.save_weights(filename + \".weights\")\n",
        "\n",
        "\n",
        "# def load_model(filename):\n",
        "#     json_file = open(filename + '.model', 'r')\n",
        "#     loaded_model_json = json_file.read()\n",
        "#     json_file.close()\n",
        "#     # loaded_model = model_from_json(loaded_model_json)\n",
        "#     # loaded_model.load_weights(filename + \".weights\")\n",
        "#     # return loaded_model;\n",
        "\n",
        "\n",
        "def getEmbeddingLayer(EMBEDDING_DIM):\n",
        "    embeddings_index = {}\n",
        "    count = 0\n",
        "    words = []\n",
        "    f = open('/content/glove.42B.300d.txt', encoding='utf-8', errors='ignore')\n",
        "    #f = open('data/word_embeddings/glove.6B.100d.txt', encoding='utf-8')\n",
        "    # f = open('/content/drive/MyDrive/Colab Notebooks/TestCode/glove.6B.100d.txt')\n",
        "    #f = open('word_embeddings/glove.6B.100d.txt')\n",
        "    \n",
        "\n",
        "    for line in f:\n",
        "        values = line.split(' ')\n",
        "        word = values[0]\n",
        "        words.append(word)\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "        count = count + 1;\n",
        "    f.close()\n",
        "\n",
        "    # fin = io.open('data/word_embeddings/GoogleNews-vectors-negative300.bin', 'r', encoding='utf-8', newline='\\n',\n",
        "    #               errors='ignore')\n",
        "    # n, d = map(int, fin.readline().split())\n",
        "    # for line in fin:\n",
        "    #     tokens = line.rstrip().split(' ')\n",
        "    #     word = tokens[0]\n",
        "    #     words.append(word)\n",
        "    #     embeddings_index[tokens[0]] = map(float, tokens[1:])\n",
        "    #     count += 1\n",
        "    # fin.close()\n",
        "\n",
        "    tokenizer_obj = Tokenizer(num_words=len(words)) #MAX_NB_WORDS\n",
        "    # tokenizer = Tokenizer(num_words=len(words))\n",
        "    tokenizer_obj.fit_on_texts(words)\n",
        "    word_index = tokenizer_obj.word_index\n",
        "    vocab_size = len(word_index) + 1\n",
        "\n",
        "    print(\"total words embeddings is \", count, len(word_index))\n",
        "    embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        if i > vocab_size - 1:\n",
        "            break\n",
        "        else:\n",
        "            embedding_vector = embeddings_index.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                # words not found in embedding index will be all-zeros.\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    embedding_layer = Embedding(input_dim=vocab_size,\n",
        "                                output_dim=EMBEDDING_DIM,\n",
        "                                weights=[embedding_matrix],\n",
        "                                input_length=MAX_SEQUENCE_LENGTH,\n",
        "                                trainable=False)\n",
        "\n",
        "    return tokenizer_obj, embedding_layer\n",
        "\n",
        "\n",
        "def create_embedded_model(embedding_layer, num_classes, MAX_SEQUENCE_LENGTH, EMBEDDING_DIM):\n",
        "    input = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
        "    emb_layer = embedding_layer(input)\n",
        "    # out1 = Bidirectional(LSTM(32, return_sequences=True, return_state=False, stateful=False, dropout=0.6), merge_mode = 'concat')(emb_layer)\n",
        "    out1 = LSTM(neurons, return_sequences=False, return_state=False, stateful=False, dropout=dropout)(emb_layer)\n",
        "    # crf = tfa.keras.layers.CRF(32)(out1)\n",
        "    output = Dense(2, activation='sigmoid')(out1)\n",
        "    model = Model(input, output)\n",
        "    print(model.summary())\n",
        "    return model;\n",
        "\n",
        "\n",
        "# Start here\n",
        "\n",
        "dataframe = pd.DataFrame()\n",
        "# dataframe = pd.read_csv('./data/atis-intent.csv', encoding='ISO-8859-1', sep=',')\n",
        "#dataframe = pd.read_csv('./data/dstc8.csv', encoding='ISO-8859-1', sep='^', engine='python')\n",
        "#dataframe = pd.read_csv(\"./data/sgd single-domains/sgd_act_Flights.csv\", encoding='ISO-8859-1', sep='^', engine='python')\n",
        "#dataframe = pd.read_csv(\"data/sgd single-domains/sgd-act-prec1-Flights.csv\", encoding='ISO-8859-1', sep='^', engine='python')\n",
        "dataframe = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/sarcasm_v2(0-1).csv\", encoding='ISO-8859-1', sep=',', engine='python')\n",
        "#dataframe = pd.read_csv(\"sarcasm_v2(0-1).csv\", encoding='ISO-8859-1', sep=',', engine='python')\n",
        "\n",
        "print(dataframe.head())\n",
        "# dataframe = dataframe.replace(to_replace=r'\\s,,\\s', value=' ')\n",
        "print(dataframe.size)\n",
        "\n",
        "#cols = ['dialogue','text','label']\n",
        "#cols = ['dialogue', 'text', 'prec_utt', 'prec_intent', 'label']\n",
        "cols = ['Corpus', 'Label', 'ID', 'Quote Text', 'Response Text']\n",
        "dataframe.columns = cols\n",
        "#D = dataframe.loc[:, 'dialogue']\n",
        "#X = dataframe.loc[:, 'text']\n",
        "#A = dataframe.loc[:, 'prec_utt']\n",
        "#B = dataframe.loc[:, 'prec_intent']\n",
        "#Y = dataframe.loc[:, 'label']\n",
        "\n",
        "#D = dataframe.loc[:, 'Corpus']\n",
        "Y = dataframe.loc[:, 'Label']\n",
        "#B = dataframe.loc[:, 'ID']\n",
        "A = dataframe.loc[:, 'Quote Text']\n",
        "X = dataframe.loc[:, 'Response Text']\n",
        "\n",
        "print(dataframe.shape)\n",
        "#X = X.reshape((len(X),1))\n",
        "\n",
        "X_featured = []\n",
        "for i in range(X.count()):\n",
        "    X_featured.append(X[i] + ' ' + A[i])\n",
        "  #X_featured.append(X[i] + ' ' + A[i] + ' ' + B[i])\n",
        "X_featured = np.reshape(X_featured, X.shape)\n",
        "#print(X_featured.shape)\n",
        "#print(dataframe.shape)\n",
        "# X = X.reshape((len(X),1))\n",
        "print(X.count())\n",
        "print(Y.count())\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = max([len(s.split()) for s in X])\n",
        "tokenizer, embedding_layer = getEmbeddingLayer(EMBEDDING_DIM)\n",
        "\n",
        "sequences_x = tokenizer.texts_to_sequences(X_featured) #X_featured\n",
        "# sequences_a = tokenizer.texts_to_sequences(A)\n",
        "# sequences_b = tokenizer.texts_to_sequences(B)\n",
        "# #sequences_a2 = tokenizer.texts_to_sequences(A2)\n",
        "# #sequences_b2 = tokenizer.texts_to_sequences(B2)\n",
        "# print(sequences_x)\n",
        "# print(sequences_a)\n",
        "# print(sequences_b)\n",
        "#dd = pad_sequences(sequences_d, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "data = pad_sequences(sequences_x, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating=\"post\")\n",
        "# aa = pad_sequences(sequences_a, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "# bb = pad_sequences(sequences_b, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "# #aa2 = pad_sequences(sequences_a2, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "# #bb2 = pad_sequences(sequences_b2, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "# print(xx)\n",
        "# print(aa)\n",
        "# print(bb)\n",
        "# d = np.transpose(d)\n",
        "# data = xx * aa * bb\n",
        "print(data)\n",
        "uniques, ids = np.unique(Y, return_inverse=True)\n",
        "y_train = tf.keras.utils.to_categorical(ids, len(uniques))\n",
        "# y_train = np.reshape(y_train, (Y.count(),len(uniques)))\n",
        "# y_train = keras.utils.to_categorical(Y,Y.count())\n",
        "print(uniques)\n",
        "print(y_train)\n",
        "# y_train = np.array(y_train.shape[1])\n",
        "# df = pd.DataFrame(data=y_train.data)\n",
        "# y_train = np.asarray(Y)\n",
        "print(\"Training data\")\n",
        "print(data.shape, y_train.shape)\n",
        "\n",
        "# np.random.seed(1)\n",
        "# y = np.random.randint(0, len(num_classes)-1, y_train.shape)\n",
        "# y = y[np.where(y.sum(axis=1) != 0)[0]]\n",
        "# y_new = LabelEncoder().fit_transform([''.join(str(l)) for l in y])\n",
        "# print(y_new)\n",
        "# seed = 7346\n",
        "# np.random.seed(seed)\n",
        "count = 0\n",
        "precision_list = list()\n",
        "recall_list = list()\n",
        "accuracy_list = list()\n",
        "f1_list = list()\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "historyl = list()\n",
        "\n",
        "# cross validation\n",
        "kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=0)\n",
        "#optimizer = AdamOptimizer(learning_rate=0.0001)\n",
        "#optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "for train, test in kfold.split(data, Y):\n",
        "    # x_train, x_test, Y_train, Y_test = train_test_split(data, y_train, test_size=0.8, random_state=0)\n",
        "    print(data[train].shape, y_train[train].shape)\n",
        "    count += 1\n",
        "    print('Fold: {0}'.format(count))\n",
        "    model = create_embedded_model(embedding_layer, len(uniques), MAX_SEQUENCE_LENGTH, EMBEDDING_DIM)\n",
        "\n",
        "    # adad = tf.train.AdadeltaOptimizer()\n",
        "    # adam = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer , metrics=['accuracy'])\n",
        "    print('Training...')\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience)\n",
        "    mc = ModelCheckpoint('best_model_lstm1'+str(count)+'.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "    # model.fit(np.reshape(data[train],(-1,data[train].shape[0],data[train].shape[1])), y_train[train], epochs=50, batch_size=batch_size, verbose=1, steps_per_epoch=20)  # 50 , steps_per_epoch=20\n",
        "    history = model.fit(data[train], y_train[train], validation_split=0.1, epochs=epochs, batch_size=batch_size, verbose=2, callbacks=[es, mc])  # 50 , steps_per_epoch=20\n",
        "    historyl.append(history)\n",
        "    # save_model(model, \"data/model\")\n",
        "    saved_model = load_model('best_model_lstm1'+str(count)+'.h5')\n",
        "    # HASTA AQUÃ  OK------------------------------------------------------------\n",
        "\n",
        "    # TESTING\n",
        "    print()\n",
        "    print(\"Testing data\")\n",
        "    print(data[test].shape, y_train[test].shape)\n",
        "\n",
        "    score, acc = saved_model.evaluate(data[test], y_train[test], verbose=1)\n",
        "    print(\"acc: \", acc)\n",
        "    print(\"Accuracy: {0:.2%}\".format(acc))\n",
        "    print('Test score:', score)\n",
        "    y_predict = saved_model.predict(data[test])\n",
        "    # y_predict = np.argmax(y_predict, axis=1)\n",
        "    print(y_predict.shape)\n",
        "    labels_pred = np.argmax(np.round(y_predict),axis=1)\n",
        "    labels_train = np.argmax(y_train[test], axis=1)\n",
        "    print(labels_train)\n",
        "    print(labels_pred)\n",
        "    #print(y_train[test], np.round(y_predict))\n",
        "    accur = accuracy_score(y_train[test], np.round(y_predict))\n",
        "    # print(roc_auc_score(Y[test], y_predict, average='macro'))\n",
        "    print('Test accuracy:', accur)\n",
        "    #print(confusion_matrix(np.argmax(y_train[test],axis=1), np.round(y_predict).argmax(axis=1)))\n",
        "    b_acc = balanced_accuracy_score(labels_train, labels_pred)\n",
        "    recall = recall_score(labels_train, labels_pred, average='weighted')\n",
        "    precision = precision_score(labels_train, labels_pred, average='weighted')\n",
        "    f1 = f1_score(labels_train, labels_pred, average='weighted')\n",
        "    print('Test b_acc:', b_acc)\n",
        "    print('Test precision:', precision)\n",
        "    print('Test recall:', recall)\n",
        "    print('Test f1:', f1)\n",
        "    accuracy_list.append(b_acc)\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "    print(history.history.keys())\n",
        "    plt.plot(history.history['loss'], color='blue')\n",
        "    plt.plot(history.history['val_loss'], color='red')\n",
        "    #plt.title(str(count))\n",
        "    #plt.show()\n",
        "    #fig.savefig(str(count)+'.png', bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#plt.boxplot(accuracy_list)\n",
        "#plt.show()\n",
        "#fig.savefig('box.png', bbox_inches='tight', pad_inches=0)\n",
        "print('avg b_accuracy precision recall f1')\n",
        "# print('avg b_accuracy {0}'.format(np.average(accuracy_list)))\n",
        "# print('avg precision {0}'.format(np.average(precision_list)))\n",
        "# print('avg recall {0}'.format(np.average(recall_list)))\n",
        "# print('avg f1 {0}'.format(np.average(f1_list)))\n",
        "print(np.average(accuracy_list))\n",
        "print(np.average(precision_list))\n",
        "print(np.average(recall_list))\n",
        "f1_final = np.average(f1_list)\n",
        "print(f1_final)\n",
        "\n",
        "fig.savefig('loss-lstm (optimizer='+str('adam')+', dropout='+str(dropout)+', neurons='+str(neurons)+', patience='+str(patience)+', epocas='+str(epochs)+', batch_size='+str(batch_size)+', folds='+str(folds)+', f1=' + str(f1_final)+ ', learning_rate'+ str(learning_rate)+').png', bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "#plt.figure()"
      ]
    }
  ]
}
